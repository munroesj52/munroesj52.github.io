<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>POWER Vector Library Manual: POWER Vector Library (pveclib)</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">POWER Vector Library Manual
   &#160;<span id="projectnumber">1.0.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">POWER Vector Library (pveclib) </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>A library of useful vector functions for POWER. This library fills in the gap between the instructions defined in the POWER Instruction Set Architecture (<b>PowerISA</b>) and major application libraries like ESSL and MASSV. The C/C++ language compilers (that support PowerISA) may implement vector intrinsic functions (compiler built-ins as embodied by altivec.h). These vector intrinsics offer an alternative to assembler programming, but do not offer higher function then that already provided by the PowerISA. </p><dl class="section author"><dt>Authors</dt><dd>Steven Munroe</dd></dl>
<h1><a class="anchor" id="Rationale"></a>
Rationale</h1>
<p>Higher level vector intrinsic operations are needed. One key reason is to smooth over the high complexity of the evolving PowerISA and compiler support.</p>
<p>For example: the PowerISA 2.07 (POWER8) provides population count and count leading zero operations on vectors of byte, halfword, word, and doubleword elements but not on the whole vector as a __int128 value. Before PowerISA 2.07, neither operation was supported, for any element size.</p>
<p>Another example: The original <b>Altivec</b> (AKA Vector Multimedia Extension (<b>VMX</b>)) provided Vector Multiply Odd / Even operations for signed / unsigned byte and halfword elements. The PowerISA 2.07 added Vector Multiply Even/Odd operations for signed / unsigned word elements. This release also added a Vector Multiply Unsigned Word Modulo operation. This was important to allow auto vectorization of C loops using 32-bit (int) multiply.</p>
<p>But PowerISA 2.07 did not add support for doubleword or quadword (__int128) multiply directly. Nor did it fill in the missing multiply modulo operations for byte and halfword. However it did add support for doubleword and quadword add / subtract modulo, This can be helpful, if you are willing to apply grade school arithmetic (add, carry the 1) to vector elements.</p>
<p>PowerISA 3.0 (POWER9) did add a Vector Multiply-Sum Unsigned Doubleword Modulo operation. With this instruction (and a generated vector of zeros as input) you can effectively implement the simple doubleword integer multiply modulo operation in a few instructions. Similarly for Vector Multiply-Sum Unsigned Halfword Modulo. But this may not be obvious.</p>
<p>This history embodies a set of trade-offs negotiated between the Software and Processor design architects at specific points in time. But most programmers would prefer to use a set of operators applied across the supported element types and sizes.</p>
<h2><a class="anchor" id="mainpage_sub0"></a>
POWER Vector Library Goals</h2>
<p>Obviously many useful operations can be constructed from existing PowerISA operations and GCC &lt;altivec.h&gt; built-ins but the implementation may not be obvious. The optimum sequence will vary across the PowerISA levels as new instructions are added. And finally the compiler's built-in support for new PowerISA instructions evolves with the compiler's release cycle.</p>
<p>So the goal of this project is to provide well crafted implementations of useful vector and large number operations.</p>
<ul>
<li>Provide equivalent functions across versions of the PowerISA. This includes some of the most useful vector instructions added to POWER9 (PowerISA 3.0B). Many of these operations can be implemented as inline function in a few vector instructions on earlier PowerISA versions.</li>
<li>Provide equivalent functions across versions of the compiler. For example built-ins provided in later versions of the compiler can be implemented as inline functions with inline asm in earlier compiler versions.</li>
<li>Provide complete arithmetic operations across supported C types. For example multiply modulo and even/odd for int, long, and __int128.</li>
<li>Provide complete extended arithmetic (carry / extend / multiple high) operations across supported C types. For example add / subtract with carry and extend for int, long, and __int128.</li>
<li>Provide higher order functions not provided directly by the PowerISA. For example vector SIMD implementation for ASCII __isalpha, etc. As another example full __int128 implementations of Count Leading Zeros, Population Count, Shift left/right immediate, and integer divide.</li>
<li>Such implementations should be small enough to inline and allow the compiler opportunity to apply common optimization techniques.</li>
</ul>
<h3><a class="anchor" id="mainpage_sub0_1"></a>
POWER Vector Library Intrinsic headers</h3>
<p>The POWER Vector Library will be primarily delivered as C language inline functions in headers files.</p><ul>
<li><a class="el" href="vec__common__ppc_8h.html" title="Common definitions and typedef used by the collection of Power Vector Library headers. ">vec_common_ppc.h</a> Typedefs and helper macros</li>
<li><a class="el" href="vec__int128__ppc_8h.html" title="Header package containing a collection of 128-bit computation functions implemented with PowerISA VMX...">vec_int128_ppc.h</a> Operations on vector __int128 values</li>
<li><a class="el" href="vec__int64__ppc_8h.html" title="Header package containing a collection of 128-bit SIMD operations over 64-bit integer elements...">vec_int64_ppc.h</a> Operations on vector long int (64-bit) values</li>
<li><a class="el" href="vec__int32__ppc_8h.html" title="Header package containing a collection of 128-bit SIMD operations over 32-bit integer elements...">vec_int32_ppc.h</a> Operations on vector int (32-bit) values</li>
<li><a class="el" href="vec__int16__ppc_8h.html" title="Header package containing a collection of 128-bit SIMD operations over 16-bit integer elements...">vec_int16_ppc.h</a> Operations on vector short int (16-bit) values</li>
<li><a class="el" href="vec__char__ppc_8h.html" title="Header package containing a collection of char and 8-bit integer computation functions implemented wi...">vec_char_ppc.h</a> Operations on vector char (values) values</li>
<li><a class="el" href="vec__bcd__ppc_8h.html" title="Header package containing a collection of Binary Coded Decimal (BCD) computation functions implemente...">vec_bcd_ppc.h</a> Operations on vectors of Binary Code Decimal and Zoned Decimal values</li>
<li>vec_f128_ppc.h Operations on vector _Float128 values</li>
<li>vec_f64_ppc.h Operations on vector double values</li>
<li>vec_f32_ppc.h Operations on vector float values</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>The list above is more of an aspiration at this time. You will not find all of these headers or complete operation set and platform coverage in the current public github. But many of these headers do exist in private trees as we work on completing function and testing across compilers and PowerISA versions.</dd></dl>
<p>The goal is to provide high quality implementations that adapt to the specifics of the compile target (-mcpu=) and compiler (&lt;altivec.h&gt;) version you are using. Initially pveclib will focus on the GCC compiler and -mcpu=[power7|power8|power9] for Linux. Testing will focus on Little Endian (<b>powerpc64le</b> for power8 and power9 targets. Any testing for Big Endian (<b>powerpc64</b> will be initially restricted to power7 and power8 targets.</p>
<p>Expanding pveclib support beyond this list to include:</p><ul>
<li>additional compilers (ie Clang)</li>
<li>additional PPC platforms (970, power6, ...)</li>
<li>Larger functions that just happen to use vector registers (Checksum, Crypto, compress/decompress, lower precision neural networks, ...)</li>
</ul>
<p>will largely depend on additional skilled practitioners joining this project and contributing (code and platform testing) on a sustained basis.</p>
<h2><a class="anchor" id="mainpage_sub1"></a>
How pveclib is different from compiler vector built-ins</h2>
<p>The PowerPC vector built-ins evolved from the original <a href="https://www.nxp.com/docs/en/reference-manual/ALTIVECPIM.pdf">AltiVec (TM) Technology Programming Interface Manual</a> (PIM). The PIM defined the minimal extensions to the application binary interface (ABI) required to support the Vector Facility. This included new keywords (vector, pixel, bool) for defining new vector types, and new operators (built-in functions) required for any supporting and compliant C language compiler.</p>
<p>The vector built-in function support included:</p><ul>
<li>generic AltiVec operations, like vec_add()</li>
<li>specific AltiVec operations (instructions, like vec_vaddubm())</li>
<li>predicates computed from AltiVec operations, like vec_all_eq() which are also generic</li>
</ul>
<p>See <a class="el" href="index.html#mainpage_sub2">Background on the evolution of &lt;altivec.h&gt;</a> for more details.</p>
<p>There are clear advantages with the compiler implementing the vector operations as built-ins:</p><ul>
<li>The compiler can access the C language type information and vector extensions to implement the function overloading required to process generic operations.</li>
<li>Built-ins can be generated inline, which eliminates function call overhead and allows more compact code generation.</li>
<li>The compiler can then apply higher order optimization across built-ins including: Local and global register allocation. Global common subexpression elimination. Loop-invariant code motion.</li>
<li>The compiler can automatically select the best instructions for the <em>target</em> processor ISA level (from the -mcpu compiler option).</li>
</ul>
<p>While this is an improvement over writing assembler code, it does not provide much function beyond the specific operations specified in the PowerISA.</p>
<p>Another issue is that generic operations were not uniformly applicable across vector types. For example:</p><ul>
<li>vec_add / vec_sub applied to float, int, short and char.</li>
<li>Later compilers added support for double (with POWER7 and the Vector Scalar Extensions (VSX) facility)</li>
<li>Integer long (64-bit) and __int128 support for POWER8 (PowerISA 2.07B).</li>
</ul>
<p>But vec_mul / vec_div did not:</p><ul>
<li>vec_mul applied to float (and later double, with POWER7 VSX).</li>
<li>vec_mule / vec_mulo (Multiply even / odd elements) applied to [signed | unsigned] integer short and char. Later compilers added support for vector int after POWER8 added vector multiply word instructions.</li>
<li>vec_div was not included in the original PIM as Altivec (VMX) only included vector reciprocal estimate for float and no vector integer divide for any size. Later compilers added support for vec_div float / double after POWER7 (VSX) added vector divide single/double-precision instructions.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>While the processor you (plan to) use, may support the specific instructions you want to exploit, the compiler you are using may not support, the generic or specific vector operations, for the element size/types, you want to use. This is common for GCC versions installed by "Enterprise Linux" distributions. They tend to freeze the GCC version early and maintain that GCC version for long term stability. One solution is to use the <a href="https://developer.ibm.com/linuxonpower/advance-toolchain/">IBM Advance toolchain for Linux on Power</a> (AT). AT is free for download and new AT versions are released yearly (usually in August) with the latest stable GCC from that spring.</dd></dl>
<p>This all can be very frustrating, at minimum, or even a show stopper, if you are on a tight schedule for your project. Especially if you are not familiar with the evolving history of the PowerISA and supporting compilers.</p>
<h3><a class="anchor" id="mainpage_sub_1_1"></a>
What can we do about this?</h3>
<p>First the Binutils assembler is usually updated within weeks of the public release of the PowerISA document. So while your compiler may not support the latest vector operations as built-in operations, an older compiler with an updated assembler, may support the instructions as inline assembler.</p>
<p>Sequences of inline assembler instructions can be wrapped within C language static inline functions and placed in a header files for shared use. If you are careful with the input / output register <em>constraints</em> the GCC compiler can provide local register allocation and minimize parameter marshaling overhead. This is very close (in function) to a specific Altivec (built-in) operation.</p>
<dl class="section note"><dt>Note</dt><dd>Using GCC's inline assembler can be challenging even for the experienced programmer. The register constraints have grown in complexity as new facilities and categories were added. The fact that some (VMX) instructions are restricted to the original 32 Vector Registers (<b>VRs</b>) (the high half of the Vector-Scalar Registers <b>VSRs</b>), while others (Binary and Decimal Floating-Point) are restricted to the original 32 Floating-Point Registers (<b>FPRs</b> (overlapping the low half of the VSRs), and the new VSX instructions can access all 64 VSRs, is just one source of complexity. So it is very important to get your input/output constraints correct if you want inline assembler code to work correctly.</dd></dl>
<p>In-line assembler should be reserved for the first implementation using the latest PowerISA. Where possible you should use existing vector built-ins to implement specific operations for wider element types, support older hardware, or higher order operations. Again wrapping these implementations in static inline functions for collection in header files for reuse and distribution is recommended.</p>
<p>The PowerISA vector facility has all the instructions you need to implement extended precision operations for add, subtract, and multiply. Add / subtract with carry-out and permute or double vector shift and grade-school arithmetic is all you need.</p>
<p>For example the Vector Add Unsigned Quadword Modulo introduced in POWER8 (PowerISA 2.07B) can be implemented for POWER7 and earlier machines in 10-11 instructions. This uses a combination of Vector Add Unsigned Word Modulo (vadduwm), Vector Add and Write Carry-Out Unsigned Word (vaddcuw), and Vector Shift Left Double by Octet Immediate (vsldoi), to propagate the word carries through the quadword.</p>
<p>For POWER8 and later, C vector integer (modulo) multiply can be implemented in a single Vector Unsigned Word Modulo (<b>vmuluwm</b>) instruction. This was added explicitly to address vectorizing loops using int multiply in C language code. And some newer compilers do support generic vec_mul() for vector int. But this is not documented. Similarly for char (byte) and short (halfword) elements.</p>
<p>POWER8 also introduced Vector Multiply Even Signed Word (<b>vmulesw</b>) and Vector Multiply Odd Signed Word (<b>vmulosw</b>) instructions. So you would expect the generic vec_mule and vec_mulo operations to be extended to support <em>vector int</em>, as these operations have long been supported for char and short. Sadly this is not supported as of GCC 7.3. We hope to see this implemented for GCC 8.</p>
<p>So what will the compiler do for vector multiply int (modulo, even, or odd) for targeting power7? Older compilers will reject this as a <em>invalid parameter combination ...</em>. A newer compiler may implement the equivalent function in a short sequence of VMX instructions from PowerISA 2.06 or earlier. And GCC 7.3 does support vec_mul for element types char, short, and int. These sequences are in the 2-7 instruction range depending on the operation and element type. This includes some constant loads and permute control vectors that can be factored and reused across operations.</p>
<p>Once the pattern is understood it is not hard to write equivalent sequences using operations from the original &lt;altivec.h&gt;. With a little care these sequences will be compatible with older compilers and older PowerISA versions. These concepts can be extended to operations that PowerISA and the compiler does not support yet. For example; a processor that may not have multiply even/odd/modulo of the required width (word, doubleword, or quadword). This might take 10-12 instructions to implement the next element size bigger then the current processor. A full 128-bit by 128-bit multiply with 256-bit result only requires 32 instructions on a POWER8 (using multiple word even/odd).</p>
<p>Also many of the operations missing from the vector facility, exist in the Fixed-point, Floating-point, or Decimal Floating-point scalar facilities. There will be some loss of efficiency in the data transfer but compared to a complex operation like divide or decimal conversions, this can be a workable solution. On older POWER processors (before power7/8) transfers between register banks (GPR, FPR, VR) had to go through memory. But with the VSX facility (POWER7) FPRs and VRs overlap with the lower and upper halves of the 64 VSR registers. So FPR &lt;-&gt; VSR transfer are 0-2 cycles latency. And with power8 we have direct transfer (GPR &lt;-&gt; FPR | VR | VSR) instructions in the 4-5 cycle latency range.</p>
<p>For example POWER8 added Binary Coded Decimal (<b>BCD</b>) add/subtract for signed 31 digit vector values. The vector unit does not support BCD multiply / divide. But the Decimal Floating-Point (<b>DFP</b>) facility (introduced with PowerISA 2.05 and Power6) supports up to 34-digit (__Decimal128) precision and all the expected (add/subtract/multiply/divide/...) arithmetic operations. DFP also supports conversion to/from 31-digit BCD and __Decimal128 precision. This is all supported with a hardware Decimal Floating-Point Unit (<b>DFU</b>).</p>
<p>So bcd_add / bcd_sub can be generated as a single instruction on POWER8 and later, and 10-11 instructions for Power6/7. This count include the VSR &lt;-&gt; FPRp transfers, BCD &lt;-&gt; DFP conversions, and DFP add/sub. Similarly bcd_mul / bcd_div are implemented in 11 instructions using register transfer and the DFU operations for Power6/7/8.</p>
<dl class="section note"><dt>Note</dt><dd>So why does anybody care about BCD and DFP? Sometimes you get large numbers in decimal that you need converted to binary for extended computation. Sometimes you need to display the results of your extended binary computation in decimal. The multiply by 10 and BCD vector operations help simplify and speed-up these conversions.</dd></dl>
<p>And finally: Henry S. Warren's wonderful book Hacker's Delight provides inspiration for SIMD versions of; count leading zeros, population count, parity, etc.</p>
<h3><a class="anchor" id="mainpage_sub_1_2"></a>
So what can the Power Vector Library project do?</h3>
<p>Clearly the PowerISA provides multiple, extensive, and powerful computational facilities that continue to evolve and grow. But the best instruction sequence for a specific computation depends on which POWER processor(s) you have or plan to support. It can also depend on the specific compiler version you use, unless you are willing to write some of your application code in assembler. Even then you need to be aware of the PowerISA versions and when specific instructions where introduced. This can be frustrating if you just want to port your application to POWER for a quick evaluation.</p>
<p>So you would like to start evaluating how to leverage this power for key algorithms at the heart of your application.</p><ul>
<li>But you are working with an older POWER processor (until the latest POWER box is delivered).</li>
<li>Or the latest POWER machine just arrived at your site (or cloud) but you are stuck using an older/stable Linux distro version (with an older distro compiler).</li>
<li>Or you need extended precision multiply for your crypto code but you are not really an assembler level programmer (or don't want to be).</li>
<li>Or you would like to program with higher level operations to improve your own productivity.</li>
</ul>
<p>Someone with the right background (knowledge of the PowerISA, assembler level programming, compilers and the vector built-ins, ...) can solve any of the issues described above. But you don't have time for this.</p>
<p>There should be an easier way to exploit the POWER vector hardware without getting lost in the details. And this extends beyond classical vector (Single Instruction Multiple Data (SIMD)) programming to exploiting larger data width (128-bit and beyond), and larger register space (64 x 128 Vector Scalar Registers)</p>
<p>Here is an example of what can be done:</p><div class="fragment"><div class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a></div><div class="line"><a class="code" href="vec__int128__ppc_8h.html#a539de2a4426a84102471306acc571ce8">vec_adduqm</a> (<a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a> a, <a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a> b)</div><div class="line">{</div><div class="line">  <a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a> t;</div><div class="line"><span class="preprocessor">#ifdef _ARCH_PWR8</span></div><div class="line"><span class="preprocessor">#ifndef vec_vadduqm</span></div><div class="line">  __asm__(</div><div class="line">      <span class="stringliteral">&quot;vadduqm %0,%1,%2;&quot;</span></div><div class="line">      : <span class="stringliteral">&quot;=v&quot;</span> (t)</div><div class="line">      : <span class="stringliteral">&quot;v&quot;</span> (a),</div><div class="line">      <span class="stringliteral">&quot;v&quot;</span> (b)</div><div class="line">      : );</div><div class="line"><span class="preprocessor">#else</span></div><div class="line">  t = (<a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a>) vec_vadduqm (a, b);</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line"><span class="preprocessor">#else</span></div><div class="line">  <a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a> c, c2;</div><div class="line">  <a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a> z= { 0,0,0,0};</div><div class="line"></div><div class="line">  c = vec_vaddcuw ((<a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a>)a, (<a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a>)b);</div><div class="line">  t = vec_vadduwm ((<a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a>)a, (<a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a>)b);</div><div class="line">  c = vec_sld (c, z, 4);</div><div class="line">  c2 = vec_vaddcuw (t, c);</div><div class="line">  t = vec_vadduwm (t, c);</div><div class="line">  c = vec_sld (c2, z, 4);</div><div class="line">  c2 = vec_vaddcuw (t, c);</div><div class="line">  t = vec_vadduwm (t, c);</div><div class="line">  c = vec_sld (c2, z, 4);</div><div class="line">  t = vec_vadduwm (t, c);</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line">  <span class="keywordflow">return</span> ((<a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a>) t);</div><div class="line">}</div></div><!-- fragment --><p>The <b>_ARCH_PWR8</b> macro is defined by the compiler when it targets POWER8 (PowerISA 2.07) or later. This is the first processor and PowerISA level to support vector quadword add/subtract. Otherwise we need to use the vector word add modulo and vector word add and write carry-out word, to add 32-bit chunks and propagate the carries through the quadword.</p>
<p>One little detail remains. Support for vec_vadduqm was added to GCC in March of 2014, after GCC 4.8 was released and GCC 4.9's feature freeze. So the only guarantee is that this feature is in GCC 5.0 and later. At some point this change was backported to GCC 4.8 and 4.9 as it is included in the current GCC 4.8/4.9 documentation. When or if these backports where propagated to a specific Linux Distro version or update is difficult to determine. So support for this vector built-in dependes on the specific version of the GCC compiler, or if specific Distro update includes these specific backports for the GCC 4.8/4.9 compiler they support. The:</p><div class="fragment"><div class="line"><span class="preprocessor">#ifndef vec_vadduqm</span></div></div><!-- fragment --><p> C preprocessor conditional checks if the <b>vec_vadduqm</b> is defined in &lt;altivec.h&gt;. If defined we can assume that the compiler implements <b>__builtin_vec_vadduqm</b> and that &lt;altivec.h&gt; includes the macro definition:</p><div class="fragment"><div class="line"><span class="preprocessor">#define vec_vadduqm __builtin_vec_vadduqm</span></div></div><!-- fragment --><p> For <b>_ARCH_PWR7</b> and earlier we need a little grade school arithmetic using Vector Add Unsigned Word Modulo (<b>vadduwm</b>) and Vector Add and Write Carry-Out Unsigned Word (<b>vaddcuw</b>). This treats the vector __int128 as 4 32-bit binary digits. The first instruction sums each (32-bit digit) column and the second records the carry out of the high order bit. This leaves the carry bit in the original (word) column, so use a shift left to line up the carries with the next higher word.</p>
<p>To propagate any carries across all 4 (word) digits, repeat this (add / carry / shift) sequence three times. Then a final add modulo word to complete the 128-bit add. This sequence requires 10-11 instructions. The 11th instruction is a vector splat word 0 immediate, which in needed in the shift left (vsldoi) instructions. This is common in vector codes and the compiler can usually reuse this register across several blocks of code and inline functions.</p>
<p>For POWER7/8 these instructions are all 2 cycle latency and 2 per cycle throughput. The vadduwm / vaddcuw instruction pairs should issue in the same cycle and execute in parallel. So the expected latency for this sequence is 14 cycles. For POWER8 the vadduqm instruction has a 4 cycle latency.</p>
<p>Similarly for the carry / extend forms which can be combined to support wider (256, 512, 1024, ...) extended arithmetic. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="vec__int128__ppc_8h.html#ad7aaadba249ce46c4c94f78df1020da3" title="Vector Add &amp; write Carry Unsigned Quadword. ">vec_addcuq</a>, <a class="el" href="vec__int128__ppc_8h.html#a44e63f70b182d60fe03b43a80647451a" title="Vector Add Extended Unsigned Quadword Modulo. ">vec_addeuqm</a>, and <a class="el" href="vec__int128__ppc_8h.html#af18b98d2d73f1afbc439e1407c78f305" title="Vector Add Extended &amp; write Carry Unsigned Quadword. ">vec_addecuq</a></dd></dl>
<p>Another example <b>Vector Multiply-by-10 Unsigned Quadword</b>: </p><div class="fragment"><div class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a></div><div class="line"><a class="code" href="vec__int128__ppc_8h.html#a3675fa1a2334eff913df447904be78ad">vec_mul10uq</a> (<a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a> a)</div><div class="line">{</div><div class="line">  <a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a> t;</div><div class="line"><span class="preprocessor">#ifdef _ARCH_PWR9</span></div><div class="line">  __asm__(</div><div class="line">      <span class="stringliteral">&quot;vmul10uq %0,%1;\n&quot;</span></div><div class="line">      : <span class="stringliteral">&quot;=v&quot;</span> (t)</div><div class="line">      : <span class="stringliteral">&quot;v&quot;</span> (a)</div><div class="line">      : );</div><div class="line"><span class="preprocessor">#else</span></div><div class="line">  <a class="code" href="vec__common__ppc_8h.html#afb47075b07673afbf78f8c60298f3712">vui16_t</a> ts = (<a class="code" href="vec__common__ppc_8h.html#afb47075b07673afbf78f8c60298f3712">vui16_t</a>) a;</div><div class="line">  <a class="code" href="vec__common__ppc_8h.html#afb47075b07673afbf78f8c60298f3712">vui16_t</a> t10;</div><div class="line">  <a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a> t_odd, t_even;</div><div class="line">  <a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a> z = { 0, 0, 0, 0 };</div><div class="line">  t10 = vec_splat_u16(10);</div><div class="line"><span class="preprocessor">#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__</span></div><div class="line">  t_even = vec_vmulouh (ts, t10);</div><div class="line">  t_odd = vec_vmuleuh (ts, t10);</div><div class="line"><span class="preprocessor">#else</span></div><div class="line">  t_even = vec_vmuleuh(ts, t10);</div><div class="line">  t_odd = vec_vmulouh(ts, t10);</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line">  t_even = vec_sld (t_even, z, 2);</div><div class="line"><span class="preprocessor">#ifdef _ARCH_PWR8</span></div><div class="line">  t = (<a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a>) vec_vadduqm ((<a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a>) t_even, (<a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a>) t_odd);</div><div class="line"><span class="preprocessor">#else</span></div><div class="line">  t = (<a class="code" href="vec__common__ppc_8h.html#a2ff4a776536870e01b7c9e454586544b">vui32_t</a>) <a class="code" href="vec__int128__ppc_8h.html#a539de2a4426a84102471306acc571ce8">vec_adduqm</a> ((<a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a>) t_even, (<a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a>) t_odd);</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line"><span class="preprocessor">#endif</span></div><div class="line">  <span class="keywordflow">return</span> ((<a class="code" href="vec__common__ppc_8h.html#a66332b4bd68c0b5d93121f6dc0f0839b">vui128_t</a>) t);</div><div class="line">}</div></div><!-- fragment --><p>PowerISA 3.0 added this instruction and it's extend / carry forms to speed up decimal to binary conversion for large numbers.</p>
<p>Notice that under the <b>_ARCH_PWR9</b> conditional, there is no check for the specific <b>vec_vmul10uq</b> built-in. As of this writing <b>vec_vmul10uq</b> is not included in the <em>OpenPOWER ELF2 ABI</em> documentation nor in the latest GCC trunk source code.</p>
<dl class="section note"><dt>Note</dt><dd>The <em>OpenPOWER ELF2 ABI</em> does define <b>bcd_mul10</b> which (from the description) will actually generate Decimal Shift (<b>bcds</b>). This instruction shifts 4-bit nibbles (BCD digits) left or right while preserving the BCD sign nibble in bits 124-127, While this is a handy instruction to have, it is not the same operation as <b>vec_vmul10uq</b>, which is a true 128-bit binary multiply by 10. As of this writing <b>bcd_mul10</b> support is not included in the latest GCC trunk source code.</dd></dl>
<p>For <b>_ARCH_PWR8</b> and earlier we need a little grade school arithmetic using <b>Vector Multiply Even/Odd Unsigned Halfword</b>. This treats the vector __int128 as 8 16-bit binary digits. We multiply each of these 16-bit digits by 10, which is done in two (even and odd) parts. The result is 4 32-bit (2 16-bit digits) partial products for the even digits and 4 32-bit products for the odd digits. The vector register (independent of endian); the even product elements are higher order and odd product elements are lower order.</p>
<p>The even digit partial products are offset right by 16-bits in the register. If we shift the even products left 1 (16-bit) digit, the even digits are lined up in columns with the odd digits. Now we can sum across partial products to get the final 128 bit product.</p>
<p>Notice also the conditional code for endian around the <b>vec_vmulouh</b> and <b>vec_vmuleuh</b> built-ins:</p><div class="fragment"><div class="line"><span class="preprocessor">#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__</span></div></div><!-- fragment --><p> This is due to the explicit decision to support little endian (<b>LE</b>) element ordering for ELF V2 LE targets. This also changes the meaning of even / odd element numbering and the relationship to high and low (digit ordering). Basically in <b>LE</b> it is the opposite of what the corresponding instructions actually do. So EVF V2 compilers will swap even and odd during code generation. This can be helpful for porting Intel vector intrinsic codes to PowerISA.</p>
<p>But this is the wrong thing to do for this computation. For LE targets the compiler will generate code that swaps the high and low order partial products. This misaligns the digit columns and produces incorrect results. So the pveclib implementation needs to be endian sensitive and pre-swaps the partial product multiplies for LE, to get the correct results.</p>
<p>Now we are ready to sum the partial product <em>digits</em> while propagating the digit carries across the 128-bit product. For <b>_ARCH_PWR8</b> we can use <b>Vector Add Unsigned Quadword Modulo</b> which handles all the internal carries in hardware. Before <b>_ARCH_PWR8</b> we only have <b>Vector Add Unsigned Word Modulo</b> and <b>Vector Add and Write Carry-Out Unsigned Word</b>.</p>
<p>We see these instructions used in the <b>else</b> leg of the pveclib <b>vec_adduqm</b> implementation above. We can assume that this implementation is correct and tested for supported platforms. So here we use another pveclib function to complete the implementation of <b>Vector Multiply-by-10 Unsigned Quadword</b>.</p>
<p>Again similarly for the carry / extend forms which can be combined to support wider (256, 512, 1024, ...) extended decimal to binary conversions. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="vec__int128__ppc_8h.html#a8c641b0107fc3e1621ef729c04efd583" title="Vector Multiply by 10 &amp; write Carry Unsigned Quadword. ">vec_mul10cuq</a>, <a class="el" href="vec__int128__ppc_8h.html#a2245626e7b90621b33ba79b763a4215e" title="Vector Multiply by 10 extended Unsigned Quadword. ">vec_mul10euq</a>, and <a class="el" href="vec__int128__ppc_8h.html#a7ca2a6427ecb9458858b5caaac8c4dca" title="Vector Multiply by 10 Extended &amp; write Carry Unsigned Quadword. ">vec_mul10ecuq</a></dd></dl>
<p>And similarly for full 128-bit x 128-bit multiply which combined with the add quadword carry / extended forms above can be used to implement wider (256, 512, 1024, ...) multiply operations. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="vec__int128__ppc_8h.html#a9aaaf0e4c2705be1e0e8e925b09c52de" title="Vector Multiply Low Unsigned Quadword. ">vec_mulluq</a> and <a class="el" href="vec__int128__ppc_8h.html#aee5c5b2998ef105b4c6f39739748ffa8" title="Vector Multiply Unsigned double Quadword. ">vec_muludq</a></dd></dl>
<h3><a class="anchor" id="mainpage_sub_1_3"></a>
Returning extended quadword results.</h3>
<p>Extended quadword add, subtract and multiply results can exceed the width of a single 128-bit vector. A 128-bit add can product 129-bit results. A unsigned 128-bit by 128-bit multiply result can produce 256-bit results. This is simplified for the <em>modulo</em> case where any result bits above the low order 128 can be discarded. But extended arithmetic requires returning the full precision result. Returning double wide quadword results are a complication for both RISC processor and C language library design.</p>
<h4><a class="anchor" id="mainpage_sub_1_3_1"></a>
PowerISA and Implementation.</h4>
<p>For a RISC processor, encoding multiple return registers forces hard trade-offs in a fixed sized instruction format. Also building a vector register file that can support at least one (or more) double wide register writes per cycle is challenging. For a super-scalar machine with multiple vector execution pipelines the processor can issue and complete multiple instructions per cycle. As most operations return single vector results, this is a higher priority, than optimizing for double wide results.</p>
<p>The PowerISA addresses this by splitting these operations into two instructions that execute independently. Here independent means that given the same inputs, one instruction does not depend on the result of the other. Independent instructions can execute out-of-order, or if the processor has multiple vector execution pipelines, can execute (issue and complete) concurrently.</p>
<p>The original VMX implementation had Vector Add/Subtract Unsigned Word Modulo (<b>vadduwm</b> / <b>vsubuwm</b>), paired with Vector Add/Subtract and Write Carry-out Unsigned Word (<b>vaddcuw</b> / <b>vsubcuw</b>). Most usage ignores the carry-out and only uses the add/sub modulo instructions. Applications requiring extended precision, pair the add/sub modulo with add/sub write carry-out, to capture the carry and propagate it to higher order bits.</p>
<p>The (four word) carries are generated into the same <em>word lane</em> as the source addends and modulo result. Propagating the carries require a separate shift (to align the carry-out with the low order (carry-in) bit of the next higher word) and another add word modulo.</p>
<p>POWER8 (PowerISA 2.07B) added full Vector Add/Subtract Unsigned Quadword Modulo (<b>vadduqm</b> / <b>vsubuqm</b>) instructions, paired with corresponding Write Carry-out instructions. (<b>vaddcuq</b> / <b>vsubcuq</b>). A further improvement over the word instructions was the addition of three operand <em>Extend</em> forms which combined add/subtract with carry-in (<b>vaddeuqm</b>, <b>vsubeuqm</b>, <b>vaddecuq</b> and <b>vsubecuq</b>). This simplifies propagating the carry-out into higher quadword operations. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="vec__int128__ppc_8h.html#a539de2a4426a84102471306acc571ce8" title="Vector Add Unsigned Quadword Modulo. ">vec_adduqm</a>, <a class="el" href="vec__int128__ppc_8h.html#ad7aaadba249ce46c4c94f78df1020da3" title="Vector Add &amp; write Carry Unsigned Quadword. ">vec_addcuq</a>, <a class="el" href="vec__int128__ppc_8h.html#a44e63f70b182d60fe03b43a80647451a" title="Vector Add Extended Unsigned Quadword Modulo. ">vec_addeuqm</a>, <a class="el" href="vec__int128__ppc_8h.html#af18b98d2d73f1afbc439e1407c78f305" title="Vector Add Extended &amp; write Carry Unsigned Quadword. ">vec_addecuq</a></dd></dl>
<p>POWER9 (PowerISA 3.0B) added Vector Multiply-by-10 Unsigned Quadword (Modulo is implied), paired with Vector Multiply-by-10 and Write Carry-out Unsigned Quadword (<b>vmul10uq</b> / <b>vmul10cuq</b>). And the <em>Extend</em> forms (<b>vmul10euq</b> / <b>vmul10ecuq</b>) simplifies the digit (0-9) carry-in for extended precision decimal to binary conversions. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="vec__int128__ppc_8h.html#a3675fa1a2334eff913df447904be78ad" title="Vector Multiply by 10 Unsigned Quadword. ">vec_mul10uq</a>, <a class="el" href="vec__int128__ppc_8h.html#a8c641b0107fc3e1621ef729c04efd583" title="Vector Multiply by 10 &amp; write Carry Unsigned Quadword. ">vec_mul10cuq</a>, <a class="el" href="vec__int128__ppc_8h.html#a2245626e7b90621b33ba79b763a4215e" title="Vector Multiply by 10 extended Unsigned Quadword. ">vec_mul10euq</a>, <a class="el" href="vec__int128__ppc_8h.html#a7ca2a6427ecb9458858b5caaac8c4dca" title="Vector Multiply by 10 Extended &amp; write Carry Unsigned Quadword. ">vec_mul10ecuq</a></dd></dl>
<p>The VMX integer multiply operations are split into multiply even/odd instructions by element size. The product requires the next larger element size (twice as many bits). So a vector multiply byte would generate 16 halfword products (256-bits in total). Requiring separate even and odd multiply instructions cuts the total generated product bits (per instruction) in half. It also simplifies the hardware design by keeping the generated product in adjacent element lanes. So each vector multiply even or odd byte operation generates 8 halfword products (128-bits) per instruction.</p>
<p>This multiply even/odd technique applies to most element sizes from byte up to doubleword. The original VMX supports multiply even/odd byte and halfword operations. In the original VMX, arithmetic operations where restricted to byte, halfword, and word elements. Multiply halfword products fit within the integer word element. No multiply byte/halfword modulo instructions were provided, but could be implemented via a vmule, vmulo, vperm sequence.</p>
<p>POWER8 (PowerISA 2.07B) added multiply even/odd word and multiply modulo word instructions. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="vec__int32__ppc_8h.html#ac93f07d5ad73243db2771da83b50d6d8" title="Vector multiply even unsigned words. ">vec_muleuw</a>, <a class="el" href="vec__int32__ppc_8h.html#a3ca45c65b9627abfc493d4ad500a961d" title="Vector multiply odd unsigned words. ">vec_mulouw</a>, <a class="el" href="vec__int32__ppc_8h.html#ab3ea7653d4e60454b91d669e2b1bcfdf" title="Vector Multiply Unsigned Word Modulo. ">vec_muluwm</a></dd></dl>
<p>The latest PowerISA (3.0B for POWER9) does add a doubleword integer multiply via <b>Vector Multiply-Sum unsigned Doubleword Modulo</b>. This is a departure from the Multiply even/odd byte/halfword/word instructions available in earlier Power processors. But careful conditioning of the inputs can generate the equivalent of multiply even/odd unsigned doubleword. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="vec__int128__ppc_8h.html#a1d183ebd232e5826be109cdaa421aeed" title="Vector Multiply-Sum Unsigned Doubleword Modulo. ">vec_msumudm</a>, <a class="el" href="vec__int128__ppc_8h.html#a26f95e02f7b0551e3f2bb7e4b4da040d" title="Vector multiply even unsigned doublewords. ">vec_muleud</a>, <a class="el" href="vec__int128__ppc_8h.html#aa989582cbfaa7984f78a937225e92f4a" title="Vector multiply odd unsigned doublewords. ">vec_muloud</a></dd></dl>
<p>This (multiply even/odd) technique breaks down when the input element size is quadword or larger. A quadword integer multiply forces a different split. The easiest next step would be a high/low split (like the Fixed-point integer multiply). A multiply low (modulo) quadword would be a useful function. Paired with multiply high quadword provides the double quadword product. This would provide the basis for higher (multi-quadword) precision multiplies. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="vec__int128__ppc_8h.html#a9aaaf0e4c2705be1e0e8e925b09c52de" title="Vector Multiply Low Unsigned Quadword. ">vec_mulluq</a>, <a class="el" href="vec__int128__ppc_8h.html#aee5c5b2998ef105b4c6f39739748ffa8" title="Vector Multiply Unsigned double Quadword. ">vec_muludq</a></dd></dl>
<h4><a class="anchor" id="mainpage_sub_1_3_2"></a>
C Language restrictions.</h4>
<p>The Power Vector Library is implemented using C language (inline) functions and this imposes its own restrictions. Standard C language allows an arbitrary number of formal parameters and one return value per function. Parameters and return values with simple C types are normally transfered (passed / returned) efficiently in local (high performance) hardware registers. Aggregate types (struct, union, and arrays of arbitrary size) are normally handled by pointer indirection. The details are defined in the appropriate Application Binary Interface (ABI) documentation.</p>
<p>The POWER processor provides lots (96) of registers so we want to use registers wherever possible. Especially when our application is composed of collections of small functions. And more especially when these functions are small enough to inline and we want the compiler to perform local register allocation and common subexpression elimination optimizations across these functions. The PowerISA defines 3 kinds of registers;</p><ul>
<li>General Purpose Registers (GPRs),</li>
<li>Floating-point Registers (FPRs),</li>
<li>Vector registers (VRs),</li>
</ul>
<p>with 32 of each kind. We will ignore the various special registers for now.</p>
<p>The PowerPC64 64-bit ELF (and OpenPOWER ELF V2) ABIs normally pass simple arguments and return values in a single register (of the appropriate kind) per value. Arguments of aggregate types are passed as storage pointers in General Purpose Registers (GPRs).</p>
<p>The language specification, the language implementation, and the ABI provide some exceptions. The C99 language adds _Complex floating types which are composed of real and imaginary parts. GCC adds _Complex integer types. For PowerPC ABIs complex values are held in a pair of registers of the appropriate kind. C99 also adds double word integers as the <em>long long int</em> type. This only matters for PowerPC 32-bit ABIs. For PowerPC64 ABIs <em>long long</em> and <em>long</em> are both 64-bit integers and are held in 64-bit GPRs.</p>
<p>GCC also adds the __int128 type for some targets including the PowerPC64 ABIs. Values of __int128 type are held (for operations, parameter passing and function return) in 64-bit GPR pairs. GCC adds __ibm128 and _Decimal128 floating point types which are held in Floating-point Registers pairs. GCC recently added the __float128 floating point type which are held in single vector register. Similarly for vector __int128.</p>
<p>GCC defines Generic Vector Extensions that allow typedefs for vectors of various element sizes/types and generic SIMD (arithmetic, logical, and element indexing) operations. For PowerPC64 ABIs this is currently restricted to 16-byte vectors as defined in &lt;altivec.h&gt;. For currently available compilers attempts to define vector types with larger (32 or 64 byte) <em>vector_size</em> values are treated as arrays of scalar elements. Only vector_size(16) variables are passed and returned in vector registers.</p>
<p>The OpenPOWER 64-Bit ELF V2 ABI Specification makes specific provisions for passing/returning <em>homogeneous aggregates</em> of multiple like data types. Such aggregates can be passed as up to eight floating-point or vector registers. This is defined for the Little Endian ELF V2 ABI and is not applicable to Big Endian ELF V1 targets. Also current GCC versions, in common use, do not fully implement this ABI feature.</p>
<p>So we have shown that there are mechanisms for functions to return multiple vector register values. But none are really practical at this time as they not yet available (function or optimal code generation) in current GCC compilers, in common use.</p>
<p>Returning pairs of vector __int128 values as _Complex __float128 would be awkward at best. And it is not clear when or if _Complex vector __int128 will be supported. GCC's Generic Vector Extensions are only implemented for vector_size(16). And current GCC compilers can generate some sub-optimal code for passing/returning <em>homogeneous aggregates</em> as suggested in the OpenPOWER ABI.</p>
<h4><a class="anchor" id="mainpage_sub_1_3_3"></a>
Subsetting the problem.</h4>
<p>We can simplify this problem by remembering that:</p><ul>
<li>Only a subset of the pveclib functions need to return more than one 128-bit vector.</li>
<li>The PowerISA normally splits these cases into multiple instructions anyway.</li>
<li>So far these functions are small and fully inlined.</li>
</ul>
<p>So we have two (or three) options given the current state of GCC compilers in common use:</p><ul>
<li>Mimic the PowerISA and split the operation into two functions, where each function only returns (up to) 128-bits of the result.</li>
<li>Use pointer parameters to return a second vector value in addition to the function return.</li>
<li>Support both and let the user decide which works best.</li>
</ul>
<p>The add/subtract quadword operations provide good examples. For exmaple adding two 256-bit unsigned integer values and returning the 257-bit (the high / low sum and the carry)result looks like this:</p><div class="fragment"><div class="line">s1 = vec_vadduqm (a1, b1); <span class="comment">// sum low 128-bits a1+b1</span></div><div class="line">c1 = vec_vaddcuq (a1, b1); <span class="comment">// write-carry from low a1+b1</span></div><div class="line">s0 = vec_vaddeuqm (a0, b0, c1); <span class="comment">// Add-extend high 128-bits a0+b0+c1</span></div><div class="line">c0 = vec_vaddecuq (a0, b0, c1); <span class="comment">// write-carry from high a0+b0+c1</span></div></div><!-- fragment --><p> This sequence uses the built-ins from &lt;altivec.h&gt; and generates instructions that will execute on POWER8 and POWER9. The compiler must target POWER8 (-mcpu=power8) or higher. In fact the compile will fail if the target is POWER7.</p>
<p>Now let's look at the pveclib version of these operations from &lt;<a class="el" href="vec__int128__ppc_8h.html" title="Header package containing a collection of 128-bit computation functions implemented with PowerISA VMX...">vec_int128_ppc.h</a>&gt;:</p><div class="fragment"><div class="line">s1 = <a class="code" href="vec__int128__ppc_8h.html#a539de2a4426a84102471306acc571ce8">vec_adduqm</a> (a1, b1); <span class="comment">// sum low 128-bits a1+b1</span></div><div class="line">c1 = <a class="code" href="vec__int128__ppc_8h.html#ad7aaadba249ce46c4c94f78df1020da3">vec_addcuq</a> (a1, b1); <span class="comment">// write-carry from low a1+b1</span></div><div class="line">s0 = <a class="code" href="vec__int128__ppc_8h.html#a44e63f70b182d60fe03b43a80647451a">vec_addeuqm</a> (a0, b0, c1); <span class="comment">// Add-extend high 128-bits a0+b0+c1</span></div><div class="line">c0 = <a class="code" href="vec__int128__ppc_8h.html#af18b98d2d73f1afbc439e1407c78f305">vec_addecuq</a> (a0, b0, c1); <span class="comment">// write-carry from high a0+b0+c1</span></div></div><!-- fragment --><p> Looks almost the same but the operations do not use the 'v' prefix on the operation name. This sequence generates the same instructions for (-mcpu=power8) as the &lt;altivec.h&gt; version above. It will also generate a different (slightly longer) instruction sequence for (-mcpu=power7) which is functionally equivalent.</p>
<p>The pveclib &lt;<a class="el" href="vec__int128__ppc_8h.html" title="Header package containing a collection of 128-bit computation functions implemented with PowerISA VMX...">vec_int128_ppc.h</a>&gt; header also provides a coding style alternative:</p><div class="fragment"><div class="line">s1 = <a class="code" href="vec__int128__ppc_8h.html#a363fa7103ccd730c47bb34cb9f05e80b">vec_addcq</a> (&amp;c1, a1, b1);</div><div class="line">s0 = <a class="code" href="vec__int128__ppc_8h.html#a9e27910c148d525e17d099688aec9ba1">vec_addeq</a> (&amp;c0, a0, b0, c1);</div></div><!-- fragment --><p> Here vec_addcq combines the adduqm/addcuq operations into a <em>add and carry quadword</em> operation. The first parameter is a pointer to vector to receive the carry-out while the 128-bit modulo sum is the function return value. Similarly vec_addeq combines the addeuqm/addecuq operations into a <em>add with extend and carry quadword</em> operation.</p>
<p>As these functions are inlined by the compiler the implied store / reload of the carry can be converted into a simple register assignment. For (-mcpu=power8) the compiler should generate the same instruction sequence as the two previous examples.</p>
<p>For (-mcpu=power7) these functions will expand into a different (slightly longer) instruction sequence which is functionally equivalent to the instruction sequence generated for (-mcpu=power8).</p>
<p>For older processors (power7 and earlier) and under some circumstances instructions generated for this "combined form" may perform better than the "split form" equivalent from the second example. Here the compiler may not recognize all the common subexpressions, as the "split forms" are expanded before optimization.</p>
<h2><a class="anchor" id="mainpage_sub2"></a>
Background on the evolution  of &lt;altivec.h&gt;</h2>
<p>The original <a href="https://www.nxp.com/docs/en/reference-manual/ALTIVECPIM.pdf">AltiVec (TM) Technology Programming Interface Manual</a> defined the minimal vector extensions to the application binary interface (ABI), new keywords (vector, pixel, bool) for defining new vector types, and new operators (built-in functions).</p>
<ul>
<li>generic AltiVec operations, like vec_add()</li>
<li>specific AltiVec operations (instructions, like vec_addubm())</li>
<li>predicates computed from a AltiVec operation like vec_all_eq()</li>
</ul>
<p>A generic operation generates specific instructions based on the types of the actual parameters. So a generic vec_add operation, with vector char parameters, will generate the (specific) vector add unsigned byte modulo (vaddubm) instruction. Predicates are used within if statement conditional clauses to access the condition code from vector operations that set Condition Register 6 (vector SIMD compares and Decimal Integer arithmetic and format conversions).</p>
<p>The PIM defined a set of compiler built-ins for vector instructions (see section "4.4 Generic and Specific AltiVec Operations") that compilers should support. The document suggests that any required typedefs and supporting macro definitions be collected into an include file named &lt;altivec.h&gt;.</p>
<p>The built-ins defined by the PIM closely match the vector instructions of the underlying PowerISA. For example: vec_mul, vec_mule / vec_mulo, and vec_muleub / vec_muloub.</p><ul>
<li>vec_mul is defined for float and double and will (usually) generate a single instruction for the type. This is a simpler case as floating point operations usually stay in their lanes (result elements are the same size as the input operand elements).</li>
<li>vec_mule / vec_mulo (multiply even / odd) are defined for integer multiply as integer products require twice as many bits as the inputs (the results don't stay in their lane). <dl class="section user"><dt></dt><dd>The RISC philosophy resists and POWER Architecture avoids instructions that write to more than one register. So the hardware and PowerISA vector integer multiply generate even and odd product results (from even and odd input elements) from two instructions executing separately. The PIM defines and compiler supports these operations as overloaded built-ins and selects the specific instructions based on the operand (char or short) type.</dd></dl>
This is complicated as the PowerISA evolves. The original Altivec (VMX) provided vector multiply (even / odd) operations for byte (char) and halfword (short) integers. Multiple even / odd word (int) instructions were not introduced until PowerISA V2.07 (POWER8). PowerISA 2.07 also introduced vector multiply word modulo which is included under the generic vec_mul.</li>
</ul>
<p>As the PowerISA evolved adding new vector (VMX) instructions, new facilities (Vector Scalar Extended (VSX)), and specialized vector categories (little endian, AES, SHA2, RAID), these new operators were added to &lt;altivec.h&gt;. This included new specific and generic operations and additional vector element types (long (64-bit) int, __int128, double and quad precision (__Float128) float).</p>
<p>However the PIM documents were primarily focused on embedded processors and were not updated to include the vector extensions implemented by the server processors. So any documentation for new vector operations were relegated to the various compilers. This was a haphazard process and some divergence in operation naming did occur between compilers.</p>
<p>In the run up to the POWER8 launch and the OpenPOWER initiative it was recognized that switching to Little Endian would require and new and well documented Application Binary Interface (<b>ABI</b>). It was also recognized that new &lt;altivec.h&gt; extensions needed to be documented in a common place so the various compilers could implement a common vector built-in API. So ...</p>
<p>The <a href="https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture">OpenPOWER ELF V2 application binary interface (ABI)</a>: Chapter 6. Vector Programming Interfaces and Appendix A. Predefined Functions for Vector Programming document the current and proposed vector built-ins we expect all C/C++ compilers to implement for the PowerISA.</p>
<p>The ABI also defines many overloaded built-in functions as generic operations. Here the compiler selects a specific PowerISA implementation based on the operand (vector element) types. The ABI also defines the (big/little) endian behavior and the compiler may select different instructions based on the endianness of the target.</p>
<p>Also note that the vector element numbering changes between big and little endian, and so does the meaning of even and odd. Both affect what the compiler supports and the instruction sequence generated.</p><ul>
<li><b>vec_muleub</b> and <b>vec_muloub</b> (multiply even / odd unsigned byte) are examples of non-overloaded built-ins provided by the GCC compiler but not defined in the ABI. One would assume these built-ins will generate the matching instruction, however the GCC compiler will adjust the generated instruction based on the target endianness (even / odd is reversed for little endian).</li>
</ul>
<p>The ABI also defines vec_mul as an overloaded operation on integer types, where only the low order half (modulo element size) of the product is returned. The PowerISA does not provide direct multiply modulo instructions for all the integer sizes / types. So this requires a multiple-instruction sequence to implement. Also integer vec_mul is defined in the ABI as "phased in" and is only implemented in the latest GCC versions.</p>
<p>This is a small sample of the complexity we encounter programming at this low level (vector intrinsic) API. Partially this is due to RISC design philosophy where there is a trade-off of software complexity for simpler (hopefully faster) hardware design.</p>
<h2><a class="anchor" id="mainpage_sub3"></a>
pveclib is not a vector math library</h2>
<p>The pveclib does not implement general purpose vector math operations. These should continue to be developed and improved within existing projects (ie LAPACK, OpenBLAS, ATLAS and libmvec).</p>
<p>We believe that pveclib will be helpful to implementors of vector math libraries by providing a higher level, more portable, and more consistent vector interface for the PowerISA. Similarly for implementors of extended arithmetic, cryptographic, compression/decompression, and pattern matching / search libraries. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Jun 8 2018 20:43:29 for POWER Vector Library Manual by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
